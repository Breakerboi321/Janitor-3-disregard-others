from flask import Flask, request, jsonify, Response
import requests
import json
import os

app = Flask(__name__)

# Configuration
NVIDIA_API_KEY = os.environ.get('NVIDIA_API_KEY', 'your-nvidia-api-key-here')
NVIDIA_BASE_URL = os.environ.get('NVIDIA_BASE_URL', 'https://integrate.api.nvidia.com/v1')

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    try:
        data = request.json
        
        # Extract OpenAI format parameters
        messages = data.get('messages', [])
        model = data.get('model', 'meta/llama-3.1-405b-instruct')
        temperature = data.get('temperature', 0.7)
        max_tokens = data.get('max_tokens', 1024)
        stream = data.get('stream', False)
        
        # Prepare NVIDIA NIM request
        nim_payload = {
            'model': model,
            'messages': messages,
            'temperature': temperature,
            'max_tokens': max_tokens,
            'stream': stream
        }
        
        # Forward request to NVIDIA NIM
        headers = {
            'Authorization': f'Bearer {NVIDIA_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        nim_url = f'{NVIDIA_BASE_URL}/chat/completions'
        
        if stream:
            # Handle streaming response
            nim_response = requests.post(
                nim_url,
                headers=headers,
                json=nim_payload,
                stream=True
            )
            
            def generate():
                for line in nim_response.iter_lines():
                    if line:
                        yield line + b'\n'
            
            return Response(generate(), mimetype='text/event-stream')
        else:
            # Handle non-streaming response
            nim_response = requests.post(
                nim_url,
                headers=headers,
                json=nim_payload
            )
            
            return jsonify(nim_response.json()), nim_response.status_code
            
    except Exception as e:
        return jsonify({
            'error': {
                'message': str(e),
                'type': 'proxy_error'
            }
        }), 500

@app.route('/v1/models', methods=['GET'])
def list_models():
    """List available models"""
    try:
        headers = {
            'Authorization': f'Bearer {NVIDIA_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        nim_url = f'{NVIDIA_BASE_URL}/models'
        nim_response = requests.get(nim_url, headers=headers)
        
        return jsonify(nim_response.json()), nim_response.status_code
    except Exception as e:
        # Return a default model list if the endpoint fails
        return jsonify({
            'object': 'list',
            'data': [
                {
                    'id': 'meta/llama-3.1-405b-instruct',
                    'object': 'model',
                    'created': 1677610602,
                    'owned_by': 'nvidia'
                }
            ]
        })

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({'status': 'ok'})

if __name__ == '__main__':
    # Run on all interfaces so it's accessible from Android
    app.run(host='0.0.0.0', port=5000, debug=False)
